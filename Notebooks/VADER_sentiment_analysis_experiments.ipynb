{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with VADER\n",
    "\n",
    "This notebook documents the initial experiments done with the VADER sentiment analysis tool. \n",
    " \n",
    "It also contains the code used for the prediction of SemEval datasets sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rafael/Projects/vaderSentiment-master/')\n",
    "\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from vaderSentiment.vaderSentiment import normalize\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Maps compound scores to sentiment labels within a given threshold\n",
    "# returns 0 for negative, 1 for neutral and 2 for positive\n",
    "def compound_threshold(x, threshold=0.05):\n",
    "        senti = 0\n",
    "        if x >= threshold:\n",
    "            senti = 2\n",
    "        elif x <= -threshold:\n",
    "            senti = 0\n",
    "        else:\n",
    "            senti = 1\n",
    "        return senti\n",
    "    \n",
    "# Calculates the sentiment compound score for a list of sentences\n",
    "def score_compound(text, threshold=0.05):\n",
    "    \n",
    "    scores = []\n",
    "    for sentence in text:\n",
    "        compound = analyser.polarity_scores(sentence)['compound']\n",
    "        senti_score = compound_threshold(compound)\n",
    "        scores.append(senti_score)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"No, no, no. This guy is a good president.\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.325, 'neu': 0.675, 'pos': 0.0, 'compound': -0.3412}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This guy is no good president.\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.243, 'neu': 0.556, 'pos': 0.201, 'compound': -0.1531}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This guy is a good president and a bad person\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.243, 'neu': 0.556, 'pos': 0.201, 'compound': -0.1531}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This guy is a bad person and a good president\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.172, 'neu': 0.542, 'pos': 0.286, 'compound': 0.3182}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This guy is a bad person and a good president and a good father\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.107, 'neu': 0.525, 'pos': 0.368, 'compound': 0.7543}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This guy is a bad person but a good president and a good father\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.707, 'pos': 0.293, 'compound': 0.4404}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This is what you call a good person?\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.14, 'neu': 0.86, 'pos': 0.0, 'compound': -0.0772}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"In this rainy day I went to the pool.\"\n",
    "analyser.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring vader ground-truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dataset_path = \"~/Datasets/vader_data/tweets_GroundTruth.txt\"\n",
    "loaded_df = pd.read_csv(ground_truth_dataset_path, \n",
    "                            sep='\\t',\n",
    "                            header=None,\n",
    "                            names=['sentiment', 'text']\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.726316</td>\n",
       "      <td>Somehow I was blessed with some really amazing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.443299</td>\n",
       "      <td>Yay. Another good phone interview.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.873684</td>\n",
       "      <td>We were 17 deep last night &amp;amp; the love was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.857143</td>\n",
       "      <td>LMAO, AMAZING!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.154639</td>\n",
       "      <td>Two words that should die this year: Sexting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "1   2.726316  Somehow I was blessed with some really amazing...\n",
       "2   1.443299                 Yay. Another good phone interview.\n",
       "3   2.873684  We were 17 deep last night &amp; the love was ...\n",
       "4   2.857143                                     LMAO, AMAZING!\n",
       "5  -2.154639  Two words that should die this year: Sexting a..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = loaded_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_text_ds = np.array(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_labels_ds = np.array(df['sentiment'])\n",
    "target = np.array([compound_threshold(x) for x in vader_labels_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9264285714285714\n"
     ]
    }
   ],
   "source": [
    "# Getting the sentences compound_score and respective label\n",
    "vader_scores_compound = score_compound(text)\n",
    "label_score = [compound_threshold(x) for x in vader_scores_compound]\n",
    "\n",
    "# Accuracy computation\n",
    "accuracy_compound = accuracy_score(target, label_score)\n",
    "print(accuracy_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion matrix\n",
      "[[1167   72   48]\n",
      " [   5   31    4]\n",
      " [  31  149 2693]]\n",
      "\n",
      "----------------Confusion matrix report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1287\n",
      "           1       0.12      0.78      0.21        40\n",
      "           2       0.98      0.94      0.96      2873\n",
      "\n",
      "    accuracy                           0.93      4200\n",
      "   macro avg       0.69      0.87      0.70      4200\n",
      "weighted avg       0.97      0.93      0.95      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(target, label_score)\n",
    "print('----------------Confusion matrix')\n",
    "print(cm)\n",
    "print()\n",
    "print('----------------Confusion matrix report')\n",
    "print(classification_report(target, label_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of movie reviews with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_path = \"/home/rafael/Datasets/IMDB\"\n",
    "reviews_train = []\n",
    "for line in open(imdb_path + '/movie_data/full_train.txt', 'r', encoding='utf8'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open(imdb_path + '/movie_data/full_test.txt', 'r', encoding='utf8'):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.<br /><br />Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.<br /><br />I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.<br /><br />All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.<br /><br />It rates a 7.7/10 from...<br /><br />the Fiend :.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple data cleanup using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this isnt the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robins new love of the thriller but this isnt a thriller per se this is more a mystery suspense vehicle through which williams attempts to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama plays pretty much like a news report until williams character gets close to achieving his goal i must say that i was highly entertained though this movie fails to teach guide inspect or amuse it felt more like i was watching a guy williams as he was actually performing the actions from a third person perspective in other words it felt real and i was able to subscribe to the premise of the story all in all its worth a watch though its definitely not friday saturday night fare it rates a   from the fiend '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As labels are evenly balanced, the first 12.5k are movie reviews expressing positive sentiment, and the rest is expressing negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment classification using VADER tool\n",
    "\n",
    "VADER takes as input direct sentences.\n",
    "\n",
    "No complex text pre-processing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = analyser.polarity_scores(\"Today was a good day!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_threshold(scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_predict_sentiments(X):\n",
    "    scores = []\n",
    "    for sentence in X:\n",
    "        score = analyser.polarity_scores(sentence)\n",
    "        compound = 1 if score['compound'] >= 0.05 else 0\n",
    "        scores.append(compound)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_scores = vader_predict_sentiments(reviews_train_clean)\n",
    "accuracy_clean = accuracy_score(target, vader_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70028\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_scores_no_cleanup = vader_predict_sentiments(reviews_train)\n",
    "accuracy_noclean = accuracy_score(target, vader_scores_no_cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy without data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69592\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_noclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SEMEVAL twitter sentiment analysis tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_semeval_tweets(file):\n",
    "    tweets = []\n",
    "    labels = []\n",
    "    classes = {\n",
    "        'negative':0,\n",
    "        'neutral':1,\n",
    "        'positive':2\n",
    "    }\n",
    "    \n",
    "    with open(file, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            sequences = re.split(r'\\t', line)\n",
    "            tweets.append(sequences[1])\n",
    "            labels.append(classes[sequences[0]])\n",
    "    return tweets, labels\n",
    "\n",
    "def write_output(file, scores, labels):\n",
    "    with open(file, 'w') as output_file:\n",
    "        for idx, score in enumerate(scores):\n",
    "            output_file.write('\\t'.join([str(score),str(labels[idx])])+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets  3547\n",
      "Labels  3547\n",
      "Output file generated for Semeval-2013 testset with predictions for 3547 tweets.\n",
      "Tweets  1853\n",
      "Labels  1853\n",
      "Output file generated for Semeval-2014 testset with predictions for 1853 tweets.\n",
      "Tweets  2390\n",
      "Labels  2390\n",
      "Output file generated for Semeval-2015 testset with predictions for 2390 tweets.\n",
      "Tweets  20632\n",
      "Labels  20632\n",
      "Output file generated for Semeval-2016 testset with predictions for 20632 tweets.\n",
      "Tweets  12284\n",
      "Labels  12284\n",
      "Output file generated for Semeval-2017 testset with predictions for 12284 tweets.\n"
     ]
    }
   ],
   "source": [
    "semeval_test_path = '/home/rafael/Datasets/semeval/data/clean'\n",
    "semeval_output_path = '/home/rafael/Datasets/semeval/results/fulldata'\n",
    "\n",
    "semeval_years = ['2013', '2014','2015','2016','2017',]\n",
    "\n",
    "\n",
    "for year in semeval_years:\n",
    "    \n",
    "    test_file = semeval_test_path + '/test' + year + '.tsv'\n",
    "    output_file = semeval_output_path + '/vader_results' + year + '.tsv'\n",
    "    \n",
    "    tweets, labels = load_semeval_tweets(test_file)\n",
    "    \n",
    "    print('Tweets ',len(tweets))\n",
    "    print('Labels ', len(labels))\n",
    "    \n",
    "    scores = score_compound(tweets, 0.05)\n",
    "    write_output(output_file, scores, labels)\n",
    "    print('Output file generated for Semeval-{} testset with predictions for {} tweets.'.format(year, len(tweets)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The assessment for vader performance over the SemEval2017 was conducted on another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
